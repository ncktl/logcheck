{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from notebook_helper import MyCorpus, build_hybrid_model, build_callbacks, build_embedding_matrix, iteration_features\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from string import ascii_letters\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "# Keras specific\n",
    "\n",
    "#### CHANGED from import keras:\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "#####\n",
    "from keras.layers import Dense, LSTM, Embedding, Flatten, CuDNNLSTM, Bidirectional, Dropout\n",
    "\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# Gemsim\n",
    "import gensim.models\n",
    "from gensim import utils\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "\n",
    "# from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_random_forests = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Before:\\n\" ,tf.config.get_visible_devices('GPU'))\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    print(\"After:\\n\" ,tf.config.get_visible_devices('GPU'))\n",
    "except IndexError as e:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the data\n",
    "min_val = 50\n",
    "repo_name = f\"174repos_min{min_val}_max1000000\"\n",
    "# repo_name = f\"300repos_min{min_val}_max1000000\"\n",
    "# repo_name = f\"combination\"\n",
    "df = pd.read_csv('../features/'+ repo_name +'_new_keyword_expanded.csv')\n",
    "# df = pd.read_csv('../features/combination.csv')\n",
    "\n",
    "# Remove errors\n",
    "df = df[df.parent != 'b']\n",
    "df = df[df.type != 'b']\n",
    "\n",
    "no_log_cnt, log_cnt = df['contains_logging'].value_counts()\n",
    "par_vec_cnt = no_log_cnt + log_cnt\n",
    "log_ratio = log_cnt / par_vec_cnt\n",
    "print(f\"Number of parameter vecs:\\t\\t{par_vec_cnt}\")\n",
    "print(f\"without logging (negatives):\\t{no_log_cnt}\")\n",
    "print(f\"with logging (positives):\\t\\t{log_cnt}\")\n",
    "print(f\"Log ratio:\\t\\t\\t\\t\\t\\t{log_ratio * 100:.2f}%\")\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the compacted context from letters into strings of integers\n",
    "df.context = [list(map(lambda y: str(ascii_letters.index(y)), list(str(x)))) for x in df.context]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df.drop([\"location\", \"contains_logging\"], axis=1)\n",
    "# X = df.drop([\"contains_logging\"], axis=1)\n",
    "X = pd.get_dummies(X, columns=[\"type\", \"parent\"])\n",
    "y = df.contains_logging\n",
    "# Keep holdout set for testing after k-fold cross validation\n",
    "X, X_holdout, y, y_holdout = train_test_split(X, y, test_size = 0.1, stratify=y, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Word2Vec Model\n",
    "\n",
    "sentences = MyCorpus(list(df.context))\n",
    "gensim_model = gensim.models.Word2Vec(sentences=sentences, min_count=1)\n",
    "actual_vocab_size = len(gensim_model.wv.key_to_index)\n",
    "actual_vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build an embedding for each context as the mean of its words' Word2Vec vectors\n",
    "# corpus_embeddings = []\n",
    "# for doc in sentences:\n",
    "#     doc_embedding = np.zeros((len(doc), 100), dtype=np.float32)\n",
    "#     for idx, word in enumerate(doc):\n",
    "#                     doc_embedding[idx] = gensim_model.wv[word]\n",
    "#     doc_embedding = np.mean(doc_embedding, axis=0)\n",
    "#     corpus_embeddings.append(doc_embedding)\n",
    "# corpus_embeddings = np.array(corpus_embeddings)\n",
    "# df_corpus_embeddings = pd.DataFrame(corpus_embeddings, columns=[\"c\"+str(i) for i in range(100)])\n",
    "# df_corpus_embeddings.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "# vectorizer = TfidfVectorizer(token_pattern=\"\\w+\")\n",
    "# concat_context = [\" \".join(x) for x in df.context]\n",
    "# vectorize_res = vectorizer.fit_transform(concat_context)\n",
    "# df_tfidf = pd.DataFrame(vectorize_res.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "# df_tfidf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score_names = [\n",
    "    \"Balanced accuracy score\",\n",
    "    \"Precision score\",\n",
    "    \"Recall score\",\n",
    "    \"F1 Binary\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Folded Random Forest Run\n",
    "if run_random_forests:\n",
    "    X_rnd = X.drop([\"context\"], axis=1)\n",
    "    rnd_forest_sampling_strategy = 0.05\n",
    "    use_sampling = False\n",
    "    # Hyper Params\n",
    "    n_estimators = 9\n",
    "    min_samples_split = 5\n",
    "    min_samples_leaf = 1\n",
    "    max_depth = None\n",
    "    class_weight = {False: 1, True: 1}\n",
    "\n",
    "    df_regular = df.drop([\"context\"], axis=1)\n",
    "    dataframes = [\n",
    "        (\"regular\", df_regular),\n",
    "        # (\"corpus\", df_corpus_embeddings.join(pd.DataFrame(df.contains_logging))),\n",
    "        # (\"tf-idf\", df_tfidf.join(pd.DataFrame(df.contains_logging))),\n",
    "        # (\"regular+corpus\", df_regular.join(df_corpus_embeddings)),\n",
    "        # (\"regular+tfidf\", df_regular.join(df_tfidf)),\n",
    "        # (\"corpus+tfidf\", df_corpus_embeddings.join(df_tfidf).join(pd.DataFrame(df.contains_logging))),\n",
    "        # (\"regular+corpus+tfidf\", df_regular.join(df_corpus_embeddings).join(df_tfidf)),\n",
    "    ]\n",
    "\n",
    "    # for df_name, df_used in dataframes:\n",
    "    #     print(df_name)\n",
    "    # for i in [2,3,3.5,4,4.5,5]:\n",
    "    for i in [4]:\n",
    "        print(f\"Weight: {i}\")\n",
    "        class_weight = {False: 1, True: i}\n",
    "        all_scores = []\n",
    "        conf_matrices = []\n",
    "        # Split data into train and test sets\n",
    "        # X = df_used.drop([\"contains_logging\", \"location\"], axis=1)\n",
    "        # if \"regular\" in df_name:\n",
    "        #     X = pd.get_dummies(X, columns=[\"type\", \"parent\"])\n",
    "        # y = df_used.contains_logging\n",
    "\n",
    "        # classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "        # classifier = RandomForestClassifier(n_estimators=9, random_state=0)\n",
    "        skf = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "        for k_fold, (train_index, test_index) in enumerate(skf.split(X_rnd, y)):\n",
    "            print(f\"Starting fold {k_fold + 1}.\")\n",
    "            classifier = RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1,\n",
    "                                           min_samples_split=min_samples_split,\n",
    "                                           min_samples_leaf=min_samples_leaf,\n",
    "                                           max_depth=max_depth,\n",
    "                                           class_weight=class_weight)\n",
    "            X_train, X_test = X_rnd.iloc[train_index], X_rnd.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            # Undersample\n",
    "            if use_sampling:\n",
    "                # sampler = RandomUnderSampler(sampling_strategy=rnd_forest_sampling_strategy)\n",
    "                sampler = RandomOverSampler(sampling_strategy=rnd_forest_sampling_strategy)\n",
    "                X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            scores = [\n",
    "                    balanced_accuracy_score(y_test, y_pred),\n",
    "                    precision_score(y_test, y_pred),\n",
    "                    recall_score(y_test, y_pred),\n",
    "                    f1_score(y_test, y_pred, average='binary', pos_label=True)\n",
    "            ]\n",
    "            all_scores.append(scores)\n",
    "            cm = confusion_matrix(y_test, y_pred, labels=classifier.classes_)\n",
    "            conf_matrices.append(cm)\n",
    "        score_df = pd.DataFrame(all_scores, columns=score_names).mean().round(3)\n",
    "        print(score_df)\n",
    "        avg_cm = np.mean(conf_matrices, axis=0).astype(int)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=avg_cm,\n",
    "                                      display_labels=classifier.classes_)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.show()\n",
    "        out = open(\"my_approach_rnd_forest_results\", \"a\")\n",
    "        # out.write(\"Name, Timestamp, use_sampling, sampling_strategy, n_estimators, min_samples_split, class_weight, \" + \", \".join(score_names) + \"\\n\")\n",
    "        out.write(f\"{repo_name}_over, {time.ctime()}, {use_sampling}, {rnd_forest_sampling_strategy}, {n_estimators}, {min_samples_split}, {class_weight}, \" +\n",
    "                  \", \".join([str(x) for x in score_df.values]) + \"\\n\")\n",
    "        out.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data split for Tensorflow\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y, random_state=0)\n",
    "# X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(\"Negatives: \" + str(y_train[y_train == 0].shape[0]))\n",
    "# print(\"Positives: \" + str(y_train[y_train == 1].shape[0]))\n",
    "# print(\"Ratio:\\t   \" + f\"{y_train[y_train == 1].shape[0] / y_train[y_train == 0].shape[0] * 100:.2f}\" + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Smote doesn't seem to work with the context column\n",
    "# over = SMOTE(random_state=0, sampling_strategy=0.1)\n",
    "# X_train_resampled, y_train_resampled = over.fit_resample(X_train, y_train)\n",
    "\n",
    "# over = RandomOverSampler(random_state=0, sampling_strategy=0.1)\n",
    "# X_train_resampled, y_train_resampled = over.fit_resample(X_train, y_train)\n",
    "\n",
    "# sampling_strategy = 0.05\n",
    "# Choose one:\n",
    "# sampler = RandomUnderSampler(random_state=0, sampling_strategy=sampling_strategy)\n",
    "# sampler = RandomOverSampler(random_state=0, sampling_strategy=sampling_strategy)\n",
    "\n",
    "# X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(\"Negatives: \" + str(y_train_resampled[y_train_resampled == 0].shape[0]))\n",
    "# print(\"Positives: \" + str(y_train_resampled[y_train_resampled == 1].shape[0]))\n",
    "# print(\"Ratio:\\t   \" + f\"{y_train_resampled[y_train_resampled == 1].shape[0] / y_train_resampled[y_train_resampled == 0].shape[0] * 100:.2f}\" + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_train, y_train = X_train_resampled, y_train_resampled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sampling_strategy = 0.05\n",
    "sampling_strategy = 0.05\n",
    "vocab_size = actual_vocab_size + 1\n",
    "output_dims = 100\n",
    "max_length = 80\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "trainable=True\n",
    "dropout = 0.2\n",
    "val_split = 0.0\n",
    "num_nodes = 128\n",
    "callback = [\"cp\"]\n",
    "callback_monitor = 'val_f1_score'\n",
    "class_weight = \"class_weight_unsupported\"\n",
    "cmpltn_metrics = [tfa.metrics.F1Score(num_classes=1, threshold=0.5)]\n",
    "\n",
    "# Cross-validation settings\n",
    "n_splits = 3\n",
    "\n",
    "settings_hash = abs(hash(str([n_splits, sampling_strategy, vocab_size, output_dims, max_length, num_epochs, batch_size, trainable, dropout, val_split, num_nodes, callback, callback_monitor, class_weight, cmpltn_metrics]))) # TODO: DEPRECATE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "embedding_matrix = build_embedding_matrix(vocab_size, output_dims, gensim_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DEPRECATED: Not usable with k-fold cross-validation\n",
    "# Pad the context\n",
    "# padded_context = pad_sequences(np.array(X.context), maxlen=max_length, value=0.0)\n",
    "# Prepare the \"other\" input\n",
    "# other_input = X.drop([\"context\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "# Pad the context to create the context input\n",
    "# padded_inputs = pad_sequences(np.array(list(X_train.context), dtype=object), maxlen=max_length, value=0.0)  # 0.0 because it corresponds with <PAD>\n",
    "# padded_inputs_test = pad_sequences(np.array(list(X_test.context), dtype=object), maxlen=max_length, value=0.0)  # 0.0 because it corresponds with <PAD>\n",
    "# padded_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "# Prepare the \"other\" input\n",
    "# regular_inputs = X_train.drop([\"context\", \"location\"], axis=1)\n",
    "# regular_inputs_test = X_test.drop([\"context\", \"location\"], axis=1)\n",
    "# regular_inputs = X_train.drop([\"context\"], axis=1)\n",
    "# regular_inputs_test = X_test.drop([\"context\"], axis=1)\n",
    "# regular_inputs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare holdout test sets\n",
    "padded_inputs_holdout = pad_sequences(np.array(list(X_holdout.context), dtype=object), maxlen=max_length, value=0.0)\n",
    "regular_inputs_holdout = X_holdout.drop([\"context\"], axis=1)\n",
    "X_holdout_dict = {\"context\": padded_inputs_holdout, \"other\": regular_inputs_holdout}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_name = f\"{repo_name[:3]}_min{min_val}_hybrid_new_keyword_cv{n_splits}\"\n",
    "run_number = 1\n",
    "# if not os.path.isdir(f\"hybrid_models\"):\n",
    "if not os.getcwd().endswith(\"notebooks\"):\n",
    "    raise Exception(\"Bad working directory\")\n",
    "while not os.path.isdir(f\"hybrid_models/{repo_name}/run{run_number}/\"):\n",
    "    run_number += 1\n",
    "run_folder = f\"run{run_number}\"\n",
    "\n",
    "# DEBUG\n",
    "debug = False\n",
    "if debug:\n",
    "    num_epochs = 1\n",
    "    batch_size = 256\n",
    "    n_splits = 1\n",
    "    settings_hash = int((hash(str(time.ctime())) ** 2) ** 0.5)\n",
    "    run_name = f\"DEBUG_{run_name}\"\n",
    "# /DEBUG\n",
    "\n",
    "start = time.time()\n",
    "histories = []\n",
    "\n",
    "# List of (X_test_dict, y_test) of all folds\n",
    "test_sets = []\n",
    "\n",
    "model = build_hybrid_model(vocab_size, output_dims, embedding_matrix, max_length,\n",
    "                       trainable, num_nodes, dropout, X.shape[1] - 1)\n",
    "# model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=cmpltn_metrics)\n",
    "\n",
    "final_bal_acc_all, final_precision_all, final_recall_all, final_f1_all = [], [], [], []\n",
    "best_bal_acc_all, best_precision_all, best_recall_all, best_f1_all = [], [], [], []\n",
    "# K-fold cross-validation\n",
    "if n_splits == 1:\n",
    "    indices = np.arange(y.shape[0])\n",
    "    strat_train_idx, strat_val_idx = train_test_split(indices, test_size=0.25, stratify=y, random_state=0)\n",
    "    idx_iter = [(strat_train_idx, strat_val_idx)]\n",
    "else:\n",
    "    skf = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.25, random_state=0)\n",
    "    idx_iter = skf.split(X, y)\n",
    "for k_fold, (train_index, test_index) in enumerate(idx_iter):\n",
    "    print(f\"Starting fold {k_fold + 1} of {n_splits}.\")\n",
    "    prog_log = open(\"progess.log\", \"a\")\n",
    "    prog_log.write(f\"{time.ctime()} Starting fold {k_fold + 1} of {n_splits}. Settings hash: {settings_hash}\\n\")\n",
    "    prog_log.close()\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # Oversample the minority class\n",
    "    sampler = RandomOverSampler(sampling_strategy=sampling_strategy)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "    # Pad the context to create the context input\n",
    "    padded_inputs = pad_sequences(np.array(list(X_train.context), dtype=object), maxlen=max_length, value=0.0)\n",
    "    padded_inputs_test = pad_sequences(np.array(list(X_test.context), dtype=object), maxlen=max_length, value=0.0)\n",
    "    # Prepare the \"other\" input\n",
    "    regular_inputs = X_train.drop([\"context\"], axis=1)\n",
    "    regular_inputs_test = X_test.drop([\"context\"], axis=1)\n",
    "    # Put both inputs into a dict\n",
    "    X_train_dict = {\"context\": padded_inputs, \"other\": regular_inputs}\n",
    "    X_test_dict = {\"context\": padded_inputs_test, \"other\": regular_inputs_test}\n",
    "    # Append to the list of test sets\n",
    "    test_sets.append((X_test_dict, y_test))\n",
    "    # Build the callbacks\n",
    "    callbacks, model_cp_filepath = build_callbacks(callback, callback_monitor, repo_name, run_folder, k_fold, zhenhao=False)\n",
    "    # Fit the model\n",
    "    history = model.fit(\n",
    "        X_train_dict,\n",
    "        {\"logging\": y_train},\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test_dict, y_test),\n",
    "        validation_split=val_split,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    histories.append(history)\n",
    "\n",
    "    # Predict with final weights\n",
    "    pred_test= model.predict(X_test_dict, batch_size=batch_size)\n",
    "    y_pred = np.round(pred_test)\n",
    "    final_bal_acc_all.append(balanced_accuracy_score(y_test, y_pred))\n",
    "    final_precision_all.append(precision_score(y_test, y_pred))\n",
    "    final_recall_all.append(recall_score(y_test, y_pred))\n",
    "    final_f1_all.append(f1_score(y_test, y_pred))\n",
    "    # Now load the best weights and predict on test data again\n",
    "    if \"cp\" in callback:\n",
    "            model.load_weights(model_cp_filepath)\n",
    "            best_pred_test= model.predict(X_test_dict, batch_size=batch_size)\n",
    "            best_y_pred = np.round(best_pred_test)\n",
    "            best_bal_acc_all.append(balanced_accuracy_score(y_test, best_y_pred))\n",
    "            best_precision_all.append(precision_score(y_test, best_y_pred))\n",
    "            best_recall_all.append(recall_score(y_test, best_y_pred))\n",
    "            best_f1_all.append(f1_score(y_test, best_y_pred))\n",
    "\n",
    "# Determine best fold and predict on holdout set\n",
    "best_fold = np.argmax(best_f1_all)\n",
    "best_fold_filepath = f'zhenhao_models/{repo_name}/{run_folder}/fold{best_fold}'\n",
    "# best_fold_filepath = f'hybrid_models/{repo_name}/{run_folder}/fold{best_fold}'\n",
    "model.load_weights(best_fold_filepath)\n",
    "pred_holdout= model.predict(X_holdout_dict, batch_size=batch_size)\n",
    "y_pred_holdout = np.round(pred_holdout)\n",
    "\n",
    "end = time.time()\n",
    "execution_time = int(end - start)\n",
    "\n",
    "scores = [\n",
    "    run_name,\n",
    "    time.ctime(),\n",
    "    sampling_strategy,\n",
    "    max_length,\n",
    "    vocab_size,\n",
    "    batch_size,\n",
    "    trainable,\n",
    "    dropout,\n",
    "    val_split,\n",
    "    callback,\n",
    "    callback_monitor,\n",
    "    num_nodes,\n",
    "    num_epochs,\n",
    "    class_weight,\n",
    "    list(map(lambda x: x.name if callable(x) else x, cmpltn_metrics)),\n",
    "    run_folder,\n",
    "    execution_time,\n",
    "    f\"{np.mean(final_bal_acc_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(final_precision_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(final_recall_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(final_f1_all, axis=0):.3f}\"[2:],\n",
    "    f\"{np.mean(best_bal_acc_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(best_precision_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(best_recall_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(best_f1_all, axis=0):.3f}\"[2:],\n",
    "    best_fold,\n",
    "    f\"{best_f1_all[best_fold]:.3f}\"[2:],\n",
    "    f\"{balanced_accuracy_score(y_holdout, y_pred_holdout):.2f}\"[2:],\n",
    "    f\"{precision_score(y_holdout, y_pred_holdout):.2f}\"[2:],\n",
    "    f\"{recall_score(y_holdout, y_pred_holdout):.2f}\"[2:],\n",
    "    f\"{f1_score(y_holdout, y_pred_holdout):.3f}\"[2:],\n",
    "]\n",
    "out = open(\"results.txt\", \"a\")\n",
    "out.write(iteration_features + \", Final_Bal_Acc, Final_Prec, Final_Recall, Final_F1, Best_Bal_Acc, Best_Prec, Best_Recall, Best_F1, Best_Fold, Best_Fold_F1, Best_Fold_Holdout_Bal_Acc, Best_Fold_Holdout_Prec, Best_Fold_Holdout_Recall, Best_Fold_Holdout_F1 \\n\")\n",
    "out.write(str(scores).replace(\"'\", \"\")[1:-1] + \"\\n\")\n",
    "out.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a model that did well\n",
    "# checkpoint_filepath = 'zhenhao_models/174repos_min50_max1000000/4609183334028858880/fold2'\n",
    "# model.load_weights(checkpoint_filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test on the last fold's test set (bad)\n",
    "# pred_test= model.predict(X_test_dict, batch_size=batch_size)\n",
    "# y_pred = np.round(pred_test)\n",
    "# print(balanced_accuracy_score(y_test, y_pred))\n",
    "# print(precision_score(y_test, y_pred))\n",
    "# print(recall_score(y_test, y_pred))\n",
    "# print(f1_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the weights of the best fold\n",
    "# checkpoint_filepath = f'zhenhao_models/{repo_name}/{settings_hash}/fold{best_fold}'\n",
    "# checkpoint_filepath = f'hybrid_models/{repo_name}/{run_folder}/fold{best_fold}'\n",
    "# Alternatively, Load the weights of a model that did well\n",
    "# checkpoint_filepath = 'zhenhao_models/174repos_min50_max1000000/4609183334028858880/fold2'\n",
    "\n",
    "# model.load_weights(checkpoint_filepath)\n",
    "# Test on the holdout set (good)\n",
    "# pred_holdout= model.predict(X_holdout_dict, batch_size=batch_size)\n",
    "# y_pred_holdout = np.round(pred_holdout)\n",
    "# print(balanced_accuracy_score(y_holdout, y_pred_holdout))\n",
    "# print(precision_score(y_holdout, y_pred_holdout))\n",
    "# print(recall_score(y_holdout, y_pred_holdout))\n",
    "# print(f1_score(y_holdout, y_pred_holdout))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}