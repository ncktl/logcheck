{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from notebook_helper import MyCorpus, build_hybrid_model, build_callbacks, build_embedding_matrix, iteration_features, show_stats\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from string import ascii_letters\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "# Keras specific\n",
    "\n",
    "#### CHANGED from import keras:\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "#####\n",
    "from keras.layers import Dense, LSTM, Embedding, Flatten, CuDNNLSTM, Bidirectional, Dropout\n",
    "\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# Gemsim\n",
    "import gensim.models\n",
    "from gensim import utils\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "\n",
    "# from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Before:\\n\" ,tf.config.get_visible_devices('GPU'))\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    print(\"After:\\n\" ,tf.config.get_visible_devices('GPU'))\n",
    "except IndexError as e:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (17895, 29)\n",
      "Number of parameter vecs:\t\t17895\n",
      "without logging (negatives):\t17572\n",
      "with logging (positives):\t\t323\n",
      "Log ratio:\t\t\t\t\t\t1.80%\n",
      "   type  count  positives     ratio\n",
      "9     m    767         69  0.089961\n",
      "4     h    185          4  0.021622\n",
      "2     e   6970        135  0.019369\n",
      "8     l   1723         32  0.018572\n",
      "5     i    872         12  0.013761\n",
      "6     j    166          2  0.012048\n",
      "1     d   4593         53  0.011539\n",
      "7     k   1233         14  0.011354\n",
      "3     f   1190          2  0.001681\n",
      "0     c     20          0  0.000000\n",
      "10    o    176          0  0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": "     location  length  num_siblings  num_children  depth_from_def  \\\n0  15;4-16;50       2            12             2               0   \n1  19;4-60;18      42            12            13               0   \n2  26;8-26;57       1            13             1               2   \n3  30;8-30;22       1            13             1               2   \n4  34;8-34;22       1            13             1               2   \n\n                               context  contains_logging  type_c  type_d  \\\n0                                 durr                 0       0       1   \n1  deqrrerueruferuerqrrqrqrqrfrerukruu                 0       0       1   \n2                                deqrr                 0       0       0   \n3                             deqrreru                 0       0       0   \n4                          deqrrerueru                 0       0       0   \n\n   type_e  ...  parent_d  parent_e  parent_f  parent_h  parent_i  parent_j  \\\n0       0  ...         1         0         0         0         0         0   \n1       0  ...         1         0         0         0         0         0   \n2       1  ...         0         1         0         0         0         0   \n3       1  ...         0         1         0         0         0         0   \n4       1  ...         0         1         0         0         0         0   \n\n   parent_k  parent_l  parent_m  parent_o  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>length</th>\n      <th>num_siblings</th>\n      <th>num_children</th>\n      <th>depth_from_def</th>\n      <th>context</th>\n      <th>contains_logging</th>\n      <th>type_c</th>\n      <th>type_d</th>\n      <th>type_e</th>\n      <th>...</th>\n      <th>parent_d</th>\n      <th>parent_e</th>\n      <th>parent_f</th>\n      <th>parent_h</th>\n      <th>parent_i</th>\n      <th>parent_j</th>\n      <th>parent_k</th>\n      <th>parent_l</th>\n      <th>parent_m</th>\n      <th>parent_o</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15;4-16;50</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0</td>\n      <td>durr</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19;4-60;18</td>\n      <td>42</td>\n      <td>12</td>\n      <td>13</td>\n      <td>0</td>\n      <td>deqrrerueruferuerqrrqrqrqrfrerukruu</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26;8-26;57</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>deqrr</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30;8-30;22</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>deqrreru</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34;8-34;22</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>deqrrerueru</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "min_val = 50\n",
    "repo_name = f\"174_min{min_val}_alt_siblings_zhenhao.csv\"\n",
    "# repo_name = f\"web2py_zhenhao.csv\"\n",
    "df = pd.read_csv('../features/'+ repo_name)\n",
    "\n",
    "# Remove errors\n",
    "df = df[df.parent != 'b']\n",
    "df = df[df.type != 'b']\n",
    "\n",
    "# Onehot encode type and parent\n",
    "df = pd.get_dummies(df, columns=[\"type\", \"parent\"])\n",
    "\n",
    "show_stats(df)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "     location  length  num_siblings  num_children  depth_from_def  \\\n0  15;4-16;50       2            12             2               0   \n1  19;4-60;18      42            12            13               0   \n2  26;8-26;57       1            13             1               2   \n3  30;8-30;22       1            13             1               2   \n4  34;8-34;22       1            13             1               2   \n\n                                             context  contains_logging  \\\n0                                    [3, 20, 17, 17]                 0   \n1  [3, 4, 16, 17, 17, 4, 17, 20, 4, 17, 20, 5, 4,...                 0   \n2                                 [3, 4, 16, 17, 17]                 0   \n3                      [3, 4, 16, 17, 17, 4, 17, 20]                 0   \n4           [3, 4, 16, 17, 17, 4, 17, 20, 4, 17, 20]                 0   \n\n   type_c  type_d  type_e  ...  parent_d  parent_e  parent_f  parent_h  \\\n0       0       1       0  ...         1         0         0         0   \n1       0       1       0  ...         1         0         0         0   \n2       0       0       1  ...         0         1         0         0   \n3       0       0       1  ...         0         1         0         0   \n4       0       0       1  ...         0         1         0         0   \n\n   parent_i  parent_j  parent_k  parent_l  parent_m  parent_o  \n0         0         0         0         0         0         0  \n1         0         0         0         0         0         0  \n2         0         0         0         0         0         0  \n3         0         0         0         0         0         0  \n4         0         0         0         0         0         0  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>length</th>\n      <th>num_siblings</th>\n      <th>num_children</th>\n      <th>depth_from_def</th>\n      <th>context</th>\n      <th>contains_logging</th>\n      <th>type_c</th>\n      <th>type_d</th>\n      <th>type_e</th>\n      <th>...</th>\n      <th>parent_d</th>\n      <th>parent_e</th>\n      <th>parent_f</th>\n      <th>parent_h</th>\n      <th>parent_i</th>\n      <th>parent_j</th>\n      <th>parent_k</th>\n      <th>parent_l</th>\n      <th>parent_m</th>\n      <th>parent_o</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15;4-16;50</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[3, 20, 17, 17]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19;4-60;18</td>\n      <td>42</td>\n      <td>12</td>\n      <td>13</td>\n      <td>0</td>\n      <td>[3, 4, 16, 17, 17, 4, 17, 20, 4, 17, 20, 5, 4,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26;8-26;57</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[3, 4, 16, 17, 17]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30;8-30;22</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[3, 4, 16, 17, 17, 4, 17, 20]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34;8-34;22</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>2</td>\n      <td>[3, 4, 16, 17, 17, 4, 17, 20, 4, 17, 20]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the compacted context from letters into strings of integers\n",
    "df.context = [list(map(lambda y: str(ascii_letters.index(y)), list(str(x)))) for x in df.context]\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df.drop([\"location\", \"contains_logging\"], axis=1)\n",
    "y = df.contains_logging\n",
    "# Keep holdout set for testing after k-fold cross validation\n",
    "X, X_holdout, y, y_holdout = train_test_split(X, y, test_size = 0.1, stratify=y, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "26"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word2Vec Model\n",
    "sentences = MyCorpus(list(df.context))\n",
    "gensim_model = gensim.models.Word2Vec(sentences=sentences, min_count=1)\n",
    "actual_vocab_size = len(gensim_model.wv.key_to_index)\n",
    "actual_vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# sampling_strategy = 0.05\n",
    "sampling_strategy = 0.05\n",
    "vocab_size = actual_vocab_size + 1\n",
    "output_dims = 100\n",
    "max_length = 80\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "trainable=True\n",
    "dropout = 0.2\n",
    "val_split = 0.0\n",
    "num_nodes = 128\n",
    "callback = [\"cp\"]\n",
    "callback_monitor = 'val_f1_score'\n",
    "class_weight = \"class_weight_unsupported\"\n",
    "cmpltn_metrics = [tfa.metrics.F1Score(num_classes=1, threshold=0.5)]\n",
    "\n",
    "# Cross-validation settings\n",
    "n_splits = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "embedding_matrix = build_embedding_matrix(vocab_size, output_dims, gensim_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Prepare holdout test sets\n",
    "padded_inputs_holdout = pad_sequences(np.array(list(X_holdout.context), dtype=object), maxlen=max_length, value=0.0)\n",
    "regular_inputs_holdout = X_holdout.drop([\"context\"], axis=1)\n",
    "X_holdout_dict = {\"context\": padded_inputs_holdout, \"other\": regular_inputs_holdout}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_name = f\"{repo_name}_cv{n_splits}\"\n",
    "run_number = 1\n",
    "if not os.getcwd().endswith(\"notebooks\"):\n",
    "    raise Exception(\"Bad working directory\")\n",
    "while os.path.isdir(f\"my_zhenhao_models/{repo_name}/run{run_number}/\"):\n",
    "    run_number += 1\n",
    "run_folder = f\"run{run_number}\"\n",
    "\n",
    "# DEBUG\n",
    "debug = False\n",
    "if debug:\n",
    "    num_epochs = 1\n",
    "    batch_size = 256\n",
    "    n_splits = 1\n",
    "    run_folder = abs(hash(str(time.ctime())))\n",
    "    run_name = f\"DEBUG_{run_name}\"\n",
    "# /DEBUG\n",
    "\n",
    "start = time.time()\n",
    "histories = []\n",
    "test_sets = []\n",
    "\n",
    "model = build_hybrid_model(vocab_size, output_dims, embedding_matrix, max_length,\n",
    "                       trainable, num_nodes, dropout, X.shape[1] - 1)\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=cmpltn_metrics)\n",
    "\n",
    "final_bal_acc_all, final_precision_all, final_recall_all, final_f1_all = [], [], [], []\n",
    "best_bal_acc_all, best_precision_all, best_recall_all, best_f1_all = [], [], [], []\n",
    "# K-fold cross-validation\n",
    "if n_splits == 1:\n",
    "    indices = np.arange(y.shape[0])\n",
    "    strat_train_idx, strat_val_idx = train_test_split(indices, test_size=0.25, stratify=y, random_state=0)\n",
    "    idx_iter = [(strat_train_idx, strat_val_idx)]\n",
    "else:\n",
    "    skf = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.25, random_state=0)\n",
    "    idx_iter = skf.split(X, y)\n",
    "for k_fold, (train_index, test_index) in enumerate(idx_iter):\n",
    "    print(f\"Starting fold {k_fold + 1} of {n_splits}.\")\n",
    "    prog_log = open(\"progess_zhenhao.log\", \"a\")\n",
    "    prog_log.write(f\"{time.ctime()} Starting fold {k_fold + 1} of {n_splits}. Run folder: {run_folder}\\n\")\n",
    "    prog_log.close()\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # Oversample the minority class\n",
    "    sampler = RandomOverSampler(sampling_strategy=sampling_strategy)\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "    # Pad the context to create the context input\n",
    "    padded_inputs = pad_sequences(np.array(list(X_train.context), dtype=object), maxlen=max_length, value=0.0)\n",
    "    padded_inputs_test = pad_sequences(np.array(list(X_test.context), dtype=object), maxlen=max_length, value=0.0)\n",
    "    # Prepare the \"other\" input\n",
    "    regular_inputs = X_train.drop([\"context\"], axis=1)\n",
    "    regular_inputs_test = X_test.drop([\"context\"], axis=1)\n",
    "    # Put both inputs into a dict\n",
    "    X_train_dict = {\"context\": padded_inputs, \"other\": regular_inputs}\n",
    "    X_test_dict = {\"context\": padded_inputs_test, \"other\": regular_inputs_test}\n",
    "    # Append to the list of test sets\n",
    "    test_sets.append((X_test_dict, y_test))\n",
    "    # Build the callbacks\n",
    "    callbacks, model_cp_filepath = build_callbacks(callback, callback_monitor, repo_name, run_folder, k_fold, zhenhao=True)\n",
    "    # Fit the model\n",
    "    history = model.fit(\n",
    "        X_train_dict,\n",
    "        {\"logging\": y_train},\n",
    "        epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test_dict, y_test),\n",
    "        validation_split=val_split,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    histories.append(history)\n",
    "\n",
    "    # Predict with final weights\n",
    "    pred_test= model.predict(X_test_dict, batch_size=batch_size)\n",
    "    y_pred = np.round(pred_test)\n",
    "    final_bal_acc_all.append(balanced_accuracy_score(y_test, y_pred))\n",
    "    final_precision_all.append(precision_score(y_test, y_pred))\n",
    "    final_recall_all.append(recall_score(y_test, y_pred))\n",
    "    final_f1_all.append(f1_score(y_test, y_pred))\n",
    "    # Now load the best weights and predict on test data again\n",
    "    if \"cp\" in callback:\n",
    "            model.load_weights(model_cp_filepath)\n",
    "            best_pred_test= model.predict(X_test_dict, batch_size=batch_size)\n",
    "            best_y_pred = np.round(best_pred_test)\n",
    "            best_bal_acc_all.append(balanced_accuracy_score(y_test, best_y_pred))\n",
    "            best_precision_all.append(precision_score(y_test, best_y_pred))\n",
    "            best_recall_all.append(recall_score(y_test, best_y_pred))\n",
    "            best_f1_all.append(f1_score(y_test, best_y_pred))\n",
    "\n",
    "# Determine best fold and predict on holdout set\n",
    "best_fold = np.argmax(best_f1_all)\n",
    "best_fold_filepath = f'my_zhenhao_models/{repo_name}/{run_folder}/fold{best_fold}'\n",
    "model.load_weights(best_fold_filepath)\n",
    "pred_holdout= model.predict(X_holdout_dict, batch_size=batch_size)\n",
    "y_pred_holdout = np.round(pred_holdout)\n",
    "\n",
    "end = time.time()\n",
    "execution_time = int(end - start)\n",
    "\n",
    "scores = [\n",
    "    run_name,\n",
    "    time.ctime(),\n",
    "    sampling_strategy,\n",
    "    max_length,\n",
    "    vocab_size,\n",
    "    batch_size,\n",
    "    trainable,\n",
    "    dropout,\n",
    "    val_split,\n",
    "    callback,\n",
    "    callback_monitor,\n",
    "    num_nodes,\n",
    "    num_epochs,\n",
    "    class_weight,\n",
    "    list(map(lambda x: x.name if callable(x) else x, cmpltn_metrics)),\n",
    "    run_folder,\n",
    "    execution_time,\n",
    "    f\"{np.mean(final_bal_acc_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(final_precision_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(final_recall_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(final_f1_all, axis=0):.3f}\"[2:],\n",
    "    f\"{np.mean(best_bal_acc_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(best_precision_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(best_recall_all, axis=0):.2f}\"[2:],\n",
    "    f\"{np.mean(best_f1_all, axis=0):.3f}\"[2:],\n",
    "    best_fold,\n",
    "    f\"{best_f1_all[best_fold]:.3f}\"[2:],\n",
    "    f\"{balanced_accuracy_score(y_holdout, y_pred_holdout):.2f}\"[2:],\n",
    "    f\"{precision_score(y_holdout, y_pred_holdout):.2f}\"[2:],\n",
    "    f\"{recall_score(y_holdout, y_pred_holdout):.2f}\"[2:],\n",
    "    f\"{f1_score(y_holdout, y_pred_holdout):.3f}\"[2:],\n",
    "]\n",
    "out = open(\"results_zhenhao.txt\", \"a\")\n",
    "# out.write(iteration_features + \", Final_Bal_Acc, Final_Prec, Final_Recall, Final_F1, Best_Bal_Acc, Best_Prec, Best_Recall, Best_F1, Best_Fold, Best_Fold_F1, Best_Fold_Holdout_Bal_Acc, Best_Fold_Holdout_Prec, Best_Fold_Holdout_Recall, Best_Fold_Holdout_F1 \\n\")\n",
    "out.write(str(scores).replace(\"'\", \"\")[1:-1] + \"\\n\")\n",
    "out.close()\n",
    "\n",
    "prog_log = open(\"progess_zhenhao.log\", \"a\")\n",
    "prog_log.write(f\"{time.ctime()} Finished fold {n_splits}. Run folder: {run_folder}\\n\")\n",
    "prog_log.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}